[
["index.html", "A Guide to Crawl-ing with R About the Authors Preface", " A Guide to Crawl-ing with R Josh M. London and Devin S. Johnson 2017-02-18 About the Authors Drs. Josh M. London and Devin S. Johnson are researchers at the NOAA Alaska Fisheries Science Center’s Marine Mammal Laboratory in Seattle, Washington. Dr. London has over 10 years of experience programming and deploying satellite tags on phocid seals. He also has developed workflows for the management of telemetry data in R. Dr. Johnson is a leading biomatrician with expertise in the analysis of animal movement. Dr. Johnson is the lead author and developer of the R package crawl. Preface This book is being developed simultaneously with a 3-day workshop on the use of the crawl package for analysis of animal movment in R. Significant components of this book, example code, and content will change. Please use code and examples with caution and contact the authors before relying on advice, code, or examples for real-world analysis. Disclaimer This book is a scientific product and is not official communication of the Alaska Fisheries Science Center, the National Oceanic and Atmospheric Administration, or the United States Department of Commerce. All AFSC Marine Mammal Laboratory (AFSC-MML) GitHub project code is provided on an ‘as is’ basis and the user assumes responsibility for its use. AFSC-MML has relinquished control of the information and no longer has responsibility to protect the integrity, confidentiality, or availability of the information. Any claims against the Department of Commerce or Department of Commerce bureaus stemming from the use of this GitHub project will be governed by all applicable Federal law. Any reference to specific commercial products, processes, or services by service mark, trademark, manufacturer, or otherwise, does not constitute or imply their endorsement, recommendation or favoring by the Department of Commerce. The Department of Commerce seal and logo, or the seal and logo of a DOC bureau, shall not be used in any manner to imply endorsement of any commercial product or activity by DOC or the United States Government. "],
["crawl-theory.html", "1 The Mathematics and Statistics of Animal Movement 1.1 Mathematics 1.2 Statistics", " 1 The Mathematics and Statistics of Animal Movement 1.1 Mathematics 1.1.1 Discrete-time random walks 1.1.2 Correlated random walks 1.1.3 Brownian motion 1.1.4 Ornstein-Ulenbeck (OU) process 1.1.5 Stochastic differential equations 1.1.6 Integrated SDEs 1.1.7 Continuous-time CRW 1.2 Statistics 1.2.1 Maximum likelihood inference 1.2.2 Bayesian inference 1.2.3 State-space models 1.2.4 Kalman filter/smoother (KFS) 1.2.5 Practical Bayesian inference 1.2.6 Process imputation "],
["crawl-practical.html", "2 A Pragmatic Guide for Analysis with crawl 2.1 Analysis and Coding Principles 2.2 Assembling Source Data 2.3 Tidy Data for Telemetry 2.4 Preparing Input Data for crawl 2.5 Determining Your Model Parameters 2.6 Exploring and Troubleshooting Model Results 2.7 Predicting a Movement Track 2.8 Simulating Tracks from the Posterior 2.9 Visualization of Results", " 2 A Pragmatic Guide for Analysis with crawl The crawl package is designed and built with the idea that it should be accessible and useful to a research biologist with some intermediate R skills and an understanding of the basic statistical theory behind the analysis of animal movement. This portion of the book will focus on providing the user with suggested principles, workflows, and pragmatic approaches that, if followed, should make analysis with crawl more efficient and reliable. As with anything in science and R, there are a number of right ways to approach a problem. The workflows and principles outline here aren’t the only way to use crawl. However, this content has been developed after years of working with researchers and troubleshooting common issues. For most users, following this guide will prove a successful endeavor. More advanced users or those with specific needs should feel free to refer to this as a starting point but then expand to meet their need. This content is broken up in the following sections: Analysis and Coding Principles Assembling Source Data Tidy Data for Telemetry Preparing Input Data for crawl Determining Your Model Parameters Exploring and Troubleshooting Model Results Predicting a Movement Track Simulating Tracks from the Posterior Visualization of Results 2.1 Analysis and Coding Principles 2.1.1 Source Data are Read Only 2.1.2 Script Everything 2.1.3 Document Along the Way 2.1.4 Embrace the Tidyverse 2.1.5 Anticipate Errors &amp; Trap Them 2.2 Assembling Source Data 2.3 Tidy Data for Telemetry 2.4 Preparing Input Data for crawl 2.5 Determining Your Model Parameters 2.6 Exploring and Troubleshooting Model Results 2.7 Predicting a Movement Track 2.8 Simulating Tracks from the Posterior 2.9 Visualization of Results "]
]
